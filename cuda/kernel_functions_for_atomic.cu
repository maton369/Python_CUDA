/*
 * スレッド全体で配列 data の要素合計を 1 つの変数 sum に加算していくカーネル。
 * 各スレッドは自分が担当する要素 data[x] を読み、atomicAdd を使って合計に加える。
 *
 * 使い方のポイント:
 * - sum はデバイスメモリ上の単一の int 変数（長さ1の配列でも可）を想定し、
 *   カーネル起動前に 0 に初期化しておく（cudaMemset など）。
 * - atomicAdd は同時更新を直列化するためレースコンディションを防げる一方、
 *   競合が多いとスループットが低下する（性能劣化の可能性）。
 * - 大きな配列を高速に集計したい場合は、
 *   「各ブロックで共有メモリに部分和 → 各ブロックが 1 回だけ atomicAdd」
 *   のパターンが一般的（競合削減）。
 * - 32bit 整数の合計がオーバーフローしないことを確認する。必要なら 64bit (long long) 版 atomicAdd を検討。
 */

__global__ void sum_atomic(int nx, int *sum, int *data){
    // グローバルな 1 次元インデックスを計算
    // blockDim.x: ブロック内のスレッド数
    // blockIdx.x: グリッド内のブロック番号
    // threadIdx.x: ブロック内のスレッド番号
    const int x = blockDim.x * blockIdx.x + threadIdx.x;

    // 範囲外アクセスの防止
    if (x < nx){
        // 競合を避けつつ単一変数に加算するための原子的加算
        // 複数スレッドが同時に sum を更新しても正しい結果が得られる
        atomicAdd(sum, data[x]);
    }
}

/*
 * 補足:
 * - この実装は 1 要素につき 1 回の atomicAdd を行うため、要素数が多いとボトルネックになりやすい。
 *   ブロック内での並列リダクション（共有メモリ利用）→ 各ブロック代表が atomicAdd の 1 回だけ実施、
 *   という段階的集約にすると大幅に高速化できることが多い。
 * - 複数要素を 1 スレッドが処理する「グリッドストライドループ」を併用すると、
 *   ブロック/グリッド構成に依存しないスケーラブルな実装にしやすい。
 * - CUDA 12 環境でも、本カーネルの atomicAdd(int*, int) はそのまま利用可能。
 *   64bit の合計が必要な場合は atomicAdd(long long*, long long) を利用する。
 */